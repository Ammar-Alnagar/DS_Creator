# AI API Keys - Choose your preferred provider
# DeepSeek API (Recommended - High quality, affordable)
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# OpenAI-compatible APIs (OpenRouter, OpenAI, etc.)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://openrouter.ai/api/v1  # For OpenRouter, or leave empty for OpenAI
OPENAI_ORGANIZATION=your_organization_id  # Optional

# Hugging Face API (for dataset uploads)
HUGGINGFACE_API_KEY=your_huggingface_api_key_here



# Provider Configuration
API_PROVIDER=deepseek  # Options: deepseek, openai, local
DEFAULT_MODEL=deepseek-chat
# OpenAI-compatible models: gpt-4, gpt-3.5-turbo, claude-3-sonnet (via OpenRouter), etc.
# DeepSeek models: deepseek-chat, deepseek-coder

# Local Model Configuration
USE_LOCAL_MODEL=false
LOCAL_MODEL_NAME=microsoft/DialoGPT-medium
# Alternative local models: microsoft/DialoGPT-large, facebook/blenderbot-400M-distill, google/flan-t5-base

# Model Settings
TEMPERATURE=0.7
MAX_TOKENS=1000

# Generation Settings
MAX_CONVERSATIONS_PER_CHUNK=5
MIN_CONVERSATION_LENGTH=50
MAX_CONVERSATION_LENGTH=500

# Processing Settings  
CHUNK_SIZE=2000
CHUNK_OVERLAP=200
BATCH_SIZE=10

# Local Model Hardware Settings
DEVICE=auto
# Options: auto, cpu, cuda, mps
MAX_MEMORY_GB=8
LOAD_IN_8BIT=true

# Directories
INPUT_DIR=./input_pdfs
OUTPUT_DIR=./datasets
MODELS_CACHE_DIR=./models_cache

# Hugging Face Upload Settings
ENABLE_HF_UPLOAD=false
HF_REPO_NAME=your_username/your_dataset_name  # Replace with your HF repo name
HF_DATASET_PRIVATE=false
HF_COMMIT_MESSAGE=Upload medical conversation dataset

# Logging
LOG_LEVEL=INFO

# Analysis Estimation
ESTIMATED_SECONDS_PER_CHUNK_GENERATION=10.0  # Avg. seconds to generate conversations for one text chunk (used by 'analyze' command ETA) 